{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPn7YiViN9uS8+hnCho5oiB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kunalsonalkar/training-llms/blob/main/codingSelfAttention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TScJXg_sC9Ab"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "inputs = torch.tensor(\n",
        "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
        "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
        "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
        "   [0.22, 0.58, 0.33], # with     (x^4)\n",
        "   [0.77, 0.25, 0.10], # one      (x^5)\n",
        "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5Ym3DacEX6l",
        "outputId": "a59d0127-9a66-4e30-c483-be232142ce28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# computing context scores for the word 'journey'\n",
        "query = inputs[1]\n",
        "print(f\"this is query: {query}\")\n",
        "attn_scores = torch.empty(inputs.shape[0])\n",
        "for i, x_i in enumerate(inputs):\n",
        "  print(f\"This is i: {i}\")\n",
        "  print(f\"This is x_i: {x_i}\")\n",
        "  attn_scores[i] = torch.dot(x_i, query)\n",
        "  print(f\"These are attention scores: {attn_scores}\")\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R1rYFgMDC49",
        "outputId": "9e0a3e56-583b-4fc0-c4a0-9557e3ac21d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is query: tensor([0.5500, 0.8700, 0.6600])\n",
            "This is i: 0\n",
            "This is x_i: tensor([0.4300, 0.1500, 0.8900])\n",
            "These are attention scores: tensor([9.5440e-01, 3.2350e-41, 0.0000e+00, 0.0000e+00, 2.4663e-43, 0.0000e+00])\n",
            "This is i: 1\n",
            "This is x_i: tensor([0.5500, 0.8700, 0.6600])\n",
            "These are attention scores: tensor([9.5440e-01, 1.4950e+00, 0.0000e+00, 0.0000e+00, 2.4663e-43, 0.0000e+00])\n",
            "This is i: 2\n",
            "This is x_i: tensor([0.5700, 0.8500, 0.6400])\n",
            "These are attention scores: tensor([9.5440e-01, 1.4950e+00, 1.4754e+00, 0.0000e+00, 2.4663e-43, 0.0000e+00])\n",
            "This is i: 3\n",
            "This is x_i: tensor([0.2200, 0.5800, 0.3300])\n",
            "These are attention scores: tensor([9.5440e-01, 1.4950e+00, 1.4754e+00, 8.4340e-01, 2.4663e-43, 0.0000e+00])\n",
            "This is i: 4\n",
            "This is x_i: tensor([0.7700, 0.2500, 0.1000])\n",
            "These are attention scores: tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 0.0000])\n",
            "This is i: 5\n",
            "This is x_i: tensor([0.0500, 0.8000, 0.5500])\n",
            "These are attention scores: tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n",
            "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = 0.\n",
        "print(f\"This is inputs[0]: {inputs[0]}\")\n",
        "print(f\"This is query: {query}\")\n",
        "for idx, element in enumerate(inputs[0]):\n",
        "  print(f\"This is idx: {idx}\")\n",
        "  print(f\"this is query[idx]: {query[idx]}\")\n",
        "  print(f\"this is input[0][idx]: {inputs[0][idx]}\")\n",
        "  res += inputs[0][idx] * query[idx]\n",
        "  print(f\"this is res: {res}\")\n",
        "print(res)\n",
        "print(torch.dot(inputs[0], query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEYDLDsIEhrD",
        "outputId": "18d87817-017b-46ad-a647-a1afb44eddc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is inputs[0]: tensor([0.4300, 0.1500, 0.8900])\n",
            "This is query: tensor([0.5500, 0.8700, 0.6600])\n",
            "This is idx: 0\n",
            "this is query[idx]: 0.550000011920929\n",
            "this is input[0][idx]: 0.4300000071525574\n",
            "this is res: 0.23650000989437103\n",
            "This is idx: 1\n",
            "this is query[idx]: 0.8700000047683716\n",
            "this is input[0][idx]: 0.15000000596046448\n",
            "this is res: 0.367000013589859\n",
            "This is idx: 2\n",
            "this is query[idx]: 0.6600000262260437\n",
            "this is input[0][idx]: 0.8899999856948853\n",
            "this is res: 0.9544000625610352\n",
            "tensor(0.9544)\n",
            "tensor(0.9544)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the attention scores\n",
        "attn_weights_tmp = attn_scores/attn_scores.sum()\n",
        "print(attn_weights_tmp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xMpxleREiKz",
        "outputId": "1a53f44d-eac3-486e-a28e-e50c4ea79fce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Softmax normalization\n",
        "def softmax_basic(x):\n",
        "  return torch.exp(x)/torch.exp(x).sum(dim=0)\n",
        "\n",
        "attn_weights_softmax = softmax_basic(attn_scores)\n",
        "\n",
        "print(attn_weights_softmax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKBSmzrXJ61X",
        "outputId": "fc75e603-f97b-405a-d589-56f888781dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute context vector z\n",
        "query = inputs[1]\n",
        "context_vec_2 = torch.zeros(query.shape)\n",
        "for i, x_i in enumerate(inputs):\n",
        "  context_vec_2 += attn_weights_softmax[i]*x_i\n",
        "print(context_vec_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN5v1EY6LfkH",
        "outputId": "aa5f1c33-fe1f-4a5c-8029-46ffd4e150a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4419, 0.6515, 0.5683])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# computing attention scores for all input tokens\n",
        "attn_scores = torch.empty(6,6)\n",
        "for i, x_i in enumerate(inputs):\n",
        "  for j, x_j in enumerate(inputs):\n",
        "    attn_scores[i,j] = torch.dot(x_i,x_j)\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ob27r8NTOc1q",
        "outputId": "ef2d5450-ec01-4af3-cf0b-c731f5d8f705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
            "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Avoiding the slow for loops by using matrix multiplication\n",
        "attn_scores = inputs @ inputs.T\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNU6iWn9RO3K",
        "outputId": "2703f066-eafc-4c52-e6b2-46539e5f4e09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
            "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing the attention scores\n",
        "attn_weights = torch.softmax(attn_scores, dim=1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETNVKpj0SBqC",
        "outputId": "8d52b5c5-e406-4585-a5b3-80acc427feb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
            "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
            "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
            "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
            "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
            "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute context vectors\n",
        "all_context_vectors = attn_weights @ inputs\n",
        "print(all_context_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1G2WmV-SSpP",
        "outputId": "7632ba8a-3f20-4bd0-cd41-b15f8b003185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4421, 0.5931, 0.5790],\n",
            "        [0.4419, 0.6515, 0.5683],\n",
            "        [0.4431, 0.6496, 0.5671],\n",
            "        [0.4304, 0.6298, 0.5510],\n",
            "        [0.4671, 0.5910, 0.5266],\n",
            "        [0.4177, 0.6503, 0.5645]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# self attention mechanism or scaled dot product attention\n",
        "# We will take the second word as a reference to start with attention\n",
        "\n",
        "x_2 = inputs[1]\n",
        "d_in = inputs.shape[1]\n",
        "d_out = 2"
      ],
      "metadata": {
        "id": "1aXM2Sy2S3LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Weight matrices - Query, Key and Value\n",
        "torch.manual_seed(123)\n",
        "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"
      ],
      "metadata": {
        "id": "H4nYxVeOVPtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute actual query, key and value\n",
        "query_2 = x_2 @ W_query\n",
        "key_2 = x_2 @ W_key\n",
        "value_2 = x_2 @ W_value"
      ],
      "metadata": {
        "id": "8vjx8zcHVQWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(key_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHbxE2voWbzV",
        "outputId": "6e296ad6-76e2-467d-843c-5c817a36e980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4433, 1.1419])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_2)\n",
        "print(W_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xz5srk6Wp8c",
        "outputId": "9e0ca71a-e53a-4109-c121-2163afa35e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.5500, 0.8700, 0.6600])\n",
            "Parameter containing:\n",
            "tensor([[0.2961, 0.5166],\n",
            "        [0.2517, 0.6886],\n",
            "        [0.0740, 0.8665]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All the keys and values\n",
        "keys = inputs @ W_key\n",
        "values = inputs @ W_value\n",
        "print(f\"This is keys: {keys}\")\n",
        "print(f\"This is values: {values}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E81VSF5CXGbo",
        "outputId": "9d1a268c-52d6-4556-e326-6cb36393ce9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is keys: tensor([[0.3669, 0.7646],\n",
            "        [0.4433, 1.1419],\n",
            "        [0.4361, 1.1156],\n",
            "        [0.2408, 0.6706],\n",
            "        [0.1827, 0.3292],\n",
            "        [0.3275, 0.9642]])\n",
            "This is values: tensor([[0.1855, 0.8812],\n",
            "        [0.3951, 1.0037],\n",
            "        [0.3879, 0.9831],\n",
            "        [0.2393, 0.5493],\n",
            "        [0.1492, 0.3346],\n",
            "        [0.3221, 0.7863]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqpyE90BX5Ne",
        "outputId": "1fb404c9-43f6-4d04-9f7f-47fd93951c79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaIZHkjQYBkk",
        "outputId": "091869af-e15b-4525-ad7a-28f8417f75d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing attention score for second word\n",
        "keys_2 = keys[1]\n",
        "attn_score_22 = query_2.dot(keys_2)\n",
        "print(attn_score_22)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ObfUGCJYDNJ",
        "outputId": "1970bdf2-a569-47e5-f04a-ea15f0cb29ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.8524)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generalizing attention scores for all the words\n",
        "attn_scores_2 = query_2 @ keys.T\n",
        "print(attn_scores_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iW_qBhBAZAvh",
        "outputId": "28d953c5-67de-49ce-bdaa-d07e555fc1c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating attention weights for all the words (using softmax)\n",
        "# Difference from basic attention is we scale the attention scores by dividing them by the square root of embedding dimension of the keys\n",
        "d_k = keys.shape[-1]\n",
        "print(d_k)\n",
        "attn_weights_2 = torch.softmax(attn_scores_2 / d_k ** 0.5, dim=-1)\n",
        "print(attn_weights_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLAui2nWa50d",
        "outputId": "275611b3-126d-45bd-a096-e105f7de3d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Last step is to multiply value vector for each word with its attention weight and then summing to obtain the context vector\n",
        "context_vec_2 = attn_weights_2 @ values\n",
        "print(context_vec_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xmn5a1uucCl1",
        "outputId": "45f36ea2-4030-4b72-c271-bbe80a66b46b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3061, 0.8210])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J8t0wVBd8vt",
        "outputId": "e4865e76-1c1e-47d7-a60e-1a2ac90e8e48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1855, 0.8812],\n",
              "        [0.3951, 1.0037],\n",
              "        [0.3879, 0.9831],\n",
              "        [0.2393, 0.5493],\n",
              "        [0.1492, 0.3346],\n",
              "        [0.3221, 0.7863]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compact self-attention Python class\n"
      ],
      "metadata": {
        "id": "1ELpbZiEfa71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class SelfAttention_v1(nn.Module):\n",
        "  def __init__(self, d_in, d_out):\n",
        "    super().__init__()\n",
        "    self.d_out = d_out\n",
        "    self.W_query = nn.Parameter(torch.rand(d_in,d_out))\n",
        "    self.W_key = nn.Parameter(torch.rand(d_in,d_out))\n",
        "    self.W_value = nn.Parameter(torch.rand(d_in,d_out))\n",
        "\n",
        "  def forward(self, x):\n",
        "    keys = x @ self.W_key\n",
        "    queries = x @ self.W_query\n",
        "    values = x @ self.W_value\n",
        "    attn_scores = queries @ keys.T\n",
        "    attn_weights = torch.softmax(\n",
        "        attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "    context_vec = attn_weights @ values\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "9l52nhFdegXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
        "print(sa_v1(inputs)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq4jSt7Xg4u7",
        "outputId": "dda3543d-7b0e-474c-b84c-5953149656fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2996, 0.8053],\n",
            "        [0.3061, 0.8210],\n",
            "        [0.3058, 0.8203],\n",
            "        [0.2948, 0.7939],\n",
            "        [0.2927, 0.7891],\n",
            "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using nn.Linear instead of torch.rand for W_q, W_k, W_v\n",
        "\n",
        "class SelfAttention_v2(nn.Module):\n",
        "  def __init__(self, d_in, d_out, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.d_out = d_out\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    keys = self.W_key(x)\n",
        "    queries = self.W_query(x)\n",
        "    values = self.W_value(x)\n",
        "    attn_scores = queries @ keys.T\n",
        "    attn_weights = torch.softmax(attn_scores/keys.shape[-1]**0.5, dim=1)\n",
        "    context_vec = attn_weights @ values\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "M6luIM7Em6Bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(789)\n",
        "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
        "print(sa_v2(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy0HBfuNxL91",
        "outputId": "6b5f4433-f80e-412f-852c-8dcfa6337406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0739,  0.0713],\n",
            "        [-0.0748,  0.0703],\n",
            "        [-0.0749,  0.0702],\n",
            "        [-0.0760,  0.0685],\n",
            "        [-0.0763,  0.0679],\n",
            "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Causal Attention - Masking the future word token**"
      ],
      "metadata": {
        "id": "ieV1pbtUvrSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queries = sa_v2.W_query(inputs)\n",
        "keys = sa_v2.W_key(inputs)\n",
        "attn_scores = queries @ keys.T\n",
        "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1Yc0OxYplHA",
        "outputId": "ae7194fd-ab09-4d7d-9dc7-6bb36a0ff9fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],\n",
            "        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],\n",
            "        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],\n",
            "        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],\n",
            "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],\n",
            "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sa_v2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP_ZpOMGznvk",
        "outputId": "d1cc9c58-254c-4ea6-b8c5-b1a68b1bd5e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SelfAttention_v2(\n",
              "  (W_query): Linear(in_features=3, out_features=2, bias=False)\n",
              "  (W_key): Linear(in_features=3, out_features=2, bias=False)\n",
              "  (W_value): Linear(in_features=3, out_features=2, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sa_v2.W_query(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNZk6NnNzpu5",
        "outputId": "9b9cbc2a-eb6f-4d8c-da8f-1f959b2511a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6600, -0.2047],\n",
              "        [ 0.9091, -0.4471],\n",
              "        [ 0.8960, -0.4419],\n",
              "        [ 0.5034, -0.2633],\n",
              "        [ 0.4088, -0.2232],\n",
              "        [ 0.6628, -0.3292]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = attn_scores.shape[0]\n",
        "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
        "print(mask_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j58ukVCbxGeU",
        "outputId": "5c9b8631-43d9-45e0-9af9-eafef15e2099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_simple = attn_weights*mask_simple\n",
        "print(masked_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be7zPa1YyWrw",
        "outputId": "ccafbd12-8557-4053-8493-65f2b054374d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1921, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2041, 0.1659, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2036, 0.1659, 0.1662, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1869, 0.1667, 0.1668, 0.1571, 0.0000, 0.0000],\n",
            "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.0000],\n",
            "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# renormalize the weights again\n",
        "row_sums = masked_simple.sum(dim=1, keepdim=True)\n",
        "masked_simple_norm = masked_simple / row_sums\n",
        "print(masked_simple_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Doircqdl2o2O",
        "outputId": "80706826-6395-4a5d-d362-75df21a15efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
            "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
            "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
            "       grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Going with -inf values above diagonal\n",
        "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
        "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
        "print(masked)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqrR41GL3NTT",
        "outputId": "d9aecbb6-a72c-4262-8d34-238ea650c644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
            "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
            "        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n",
            "        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n",
            "        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n",
            "        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n",
            "       grad_fn=<MaskedFillBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.softmax(masked / keys.shape[-1]**0.5, dim=1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ddh5OrF34vNK",
        "outputId": "0a90e053-9a6d-40e3-e114-762f8310233a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
            "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
            "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "dropout = torch.nn.Dropout(0.5)\n",
        "example = torch.ones(6,6)\n",
        "print(dropout(example))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8v5sESZp48XC",
        "outputId": "02a68bda-b26a-4ef8-ba80-a15e2f618e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2., 2., 2., 2., 2., 2.],\n",
            "        [0., 2., 0., 0., 0., 0.],\n",
            "        [0., 0., 2., 0., 2., 0.],\n",
            "        [2., 2., 0., 0., 0., 2.],\n",
            "        [2., 0., 0., 0., 0., 2.],\n",
            "        [0., 2., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "print(dropout(attn_weights))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6Vr64kL9UaF",
        "outputId": "fda02e3e-ddc0-4f69-9612-4a256b664281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.8966, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.6206, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5517, 0.4921, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.4350, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.3327, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementing a causal attention class**"
      ],
      "metadata": {
        "id": "5yX0Dk4s96kT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = torch.stack((inputs, inputs), dim=0)\n",
        "print(batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xnt0UFsZ9oit",
        "outputId": "12178005-f02d-463a-eac4-b1a6ceeb19df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 6, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzvLYLgy_BC8",
        "outputId": "7c0db4f4-edb6-4e93-d716-10b20328088e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.4300, 0.1500, 0.8900],\n",
              "         [0.5500, 0.8700, 0.6600],\n",
              "         [0.5700, 0.8500, 0.6400],\n",
              "         [0.2200, 0.5800, 0.3300],\n",
              "         [0.7700, 0.2500, 0.1000],\n",
              "         [0.0500, 0.8000, 0.5500]],\n",
              "\n",
              "        [[0.4300, 0.1500, 0.8900],\n",
              "         [0.5500, 0.8700, 0.6600],\n",
              "         [0.5700, 0.8500, 0.6400],\n",
              "         [0.2200, 0.5800, 0.3300],\n",
              "         [0.7700, 0.2500, 0.1000],\n",
              "         [0.0500, 0.8000, 0.5500]]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalAttention(nn.Module):\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, qkv_bias = False):\n",
        "    super().__init__()\n",
        "    self.d_out = d_out\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
        "    self.W_key = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer(\n",
        "        'mask',\n",
        "        torch.triu(torch.ones(context_length, context_length),\n",
        "        diagonal=1)\n",
        "\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    b, num_tokens, d_in = x.shape\n",
        "    keys = self.W_key(x)\n",
        "    queries = self.W_query(x)\n",
        "    values = self.W_value(x)\n",
        "\n",
        "    attn_scores = queries @ keys.transpose(1,2)\n",
        "    attn_scores.masked_fill_(\n",
        "        self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
        "    attn_weights = torch.softmax(attn_scores/ keys.shape[-1]**0.5, dim=-1)\n",
        "    context_vec = attn_weights @ values\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "LKb711UX_C_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Causal Attention\n",
        "torch.manual_seed(123)\n",
        "context_length = batch.shape[1]\n",
        "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
        "context_vecs = ca(batch)\n",
        "print(context_vecs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoF9oewl8Lpz",
        "outputId": "2dd5bfcb-022d-4090-841c-50679193b482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 6, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ca"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZ7KvApkCFOU",
        "outputId": "ba014246-b5cb-4844-9b19-5cf332c72ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CausalAttention(\n",
              "  (W_query): Linear(in_features=3, out_features=2, bias=False)\n",
              "  (W_key): Linear(in_features=3, out_features=2, bias=False)\n",
              "  (W_value): Linear(in_features=3, out_features=2, bias=False)\n",
              "  (dropout): Dropout(p=0.0, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7dBjZShCGiK",
        "outputId": "ad567a07-6399-43ea-d60d-6563d1aa0fb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.4300, 0.1500, 0.8900],\n",
              "         [0.5500, 0.8700, 0.6600],\n",
              "         [0.5700, 0.8500, 0.6400],\n",
              "         [0.2200, 0.5800, 0.3300],\n",
              "         [0.7700, 0.2500, 0.1000],\n",
              "         [0.0500, 0.8000, 0.5500]],\n",
              "\n",
              "        [[0.4300, 0.1500, 0.8900],\n",
              "         [0.5500, 0.8700, 0.6600],\n",
              "         [0.5700, 0.8500, 0.6400],\n",
              "         [0.2200, 0.5800, 0.3300],\n",
              "         [0.7700, 0.2500, 0.1000],\n",
              "         [0.0500, 0.8000, 0.5500]]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Multi-head Attention"
      ],
      "metadata": {
        "id": "DqWDyeBeEApG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Just stack the single causal attention layer multiple times\n",
        "class MultiHeadAttentionWrapper(nn.Module):\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "      super().__init__()\n",
        "      self.heads = nn.ModuleList(\n",
        "          [CausalAttention(d_in, d_out, context_length, dropout, qkv_bias)\n",
        "           for _ in range(num_heads)]\n",
        "      )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.cat([head(x) for head in self.heads], dim=-1)"
      ],
      "metadata": {
        "id": "79aTxeo3CLMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "context_length = batch.shape[1]\n",
        "d_in, d_out = 3, 2\n",
        "mha = MultiHeadAttentionWrapper(d_in, d_out, context_length, 0.0, num_heads=2)\n",
        "context_vecs = mha(batch)\n",
        "\n",
        "print(context_vecs)\n",
        "print(context_vecs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0LRWDV7JBf8",
        "outputId": "12220bfd-05c8-4eda-e2c2-804fb783ae38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
            "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
            "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
            "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
            "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
            "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
            "\n",
            "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
            "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
            "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
            "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
            "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
            "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n",
            "torch.Size([2, 6, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y2wl2K8HKpH9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}